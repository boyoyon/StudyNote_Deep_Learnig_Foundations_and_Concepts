<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>17章</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
            .margin-large
            {
                margin-left: 30px;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .two-columns {
            display: flex;
            flex-direction: row;
            gap: 20px; /* 列間のスペース */
        }
        .column {
            flex: 1; /* 各列が均等に幅を取る */
        }
    </style>
<style>
.three-columns {
  display: flex;
  gap: 10px; /* 列間の余白を設定 */
}
.column {
  flex: 1; /* 各列の幅を均等にする */
  padding: 10px; /* 内側の余白を設定 */
}
</style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 0px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
            ol
            {
                margin-left: 30px;
            }
            ul
            {
                margin-left: 30px;
            }
    </style>
    <style>
        .thin-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 1px;
            background-color: gray;
        }

        .thick-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 2px;
            background-color: black;
        }
    </style>
    <style>
        .highlight {
            color: red; /* 好きな色に変更してください */
        }
    </style>
    </head>
    <body>
        <h1><center>17章 敵対的生成モデル</center></h1>
<p>
生成モデルは、機械学習アルゴリズムを使用して一連のトレーニングデータから分布を学習し、その分布から新しい例を生成します。たとえば、生成モデルは動物の画像でトレーニングされ、その後、新しい動物の画像を生成するために使用される場合があります。このような生成モデルは、分布 \(p(\mathbf x|\mathbf w)\) の観点から考えることができます。ここで、\(\mathbf x\) はデータ空間内のベクトルであり、\(\mathbf w\) はモデルの学習可能なパラメーターを表します。多くの場合、私たちは \(p(\mathbf x|\mathbf c, \mathbf w)\) という形式の条件付き生成モデルに興味を持ちます。ここで、\(\mathbf c\) は条件変数のベクトルを表します。動物画像の生成モデルの場合、生成される画像が猫や犬などの特定の動物のものであることをcの値で指定したい場合があります。
</p>
<p>
画像生成などの実世界のアプリケーションでは、分布は非常に複雑であるため、深層学習の導入により生成モデルのパフォーマンスが劇的に向上しました。トランスフォーマーに基づく自己回帰大規模言語モデルについて説明したときに、深層生成モデルの重要なクラスにすでに遭遇しました。また、非線形潜在変数モデルに基づく生成モデルの4つの重要なクラスについて概説しました。この章では、そのうちの1つ目である敵対的生成ネットワークについて説明します。他の3つのアプローチについては、後続の章で説明します。
</p>
<h2>17.1 敵対的トレーニング</h2>
<p>
潜在空間zからデータ空間xへの非線形変換に基づく生成モデルを考えてみましょう。潜在分布 \(p(\mathbf z)\) を導入します。これは単純なガウス分布の形をとる可能性があります。
\[
p(\mathbf z)=\mathcal N(\mathbf z|\mathbf 0,\mathbf I) \tag{17.1}
\]
</p>
<p>
これに、ジェネレーターとして知られる学習可能なパラメーターwを備えたディープニューラルネットワークによって定義される非線形変換 \(\mathbf x = g(\mathbf z,\mathbf w)\) が使用されます。これらを合わせて \(\mathbf x\) にわたる分布を暗黙的に定義します。私たちの目標は、この分布をトレーニング例 \(\{\mathbf x_n\}\; n = 1,...,N\) のデータセットに適合させることです。ただし、尤度関数を最適化して \(\mathbf w\) を決定することはできません。これは、一般に閉じた形式では評価できないためです。敵対的生成ネットワーク(GANs)(Goodfellow et al., 2014; Ruthotto and Haber, 2021)の重要なアイデアは、生成ネットワークと同時にトレーニングされ、生成ネットワークの重さを更新するトレーニング信号を提供する2番目の識別ネットワークを導入することです。これは図17.1に図示されています
</p>
<p>
図17.1。識別器ニューラルネットワーク \(d(\mathbf x, \boldsymbol{\phi})\) がトレーニングセットからの実際のサンプル(この場合は子猫の画像)と生成ネットワーク \(g(\mathbf z, \mathbf w)\)。ジェネレーターは、現実的な画像を生成することで識別ネットワークの誤差を最大化することを目的としていますが、識別ネットワークは実際の例と合成例をよりよく区別することで同じ誤差を最小限に抑えようとします。
</p>
<p>
識別ネットワークの目的は、データセットからの実際の例と、生成ネットワークによって生成された合成または「偽」の例を区別することであり、従来の分類誤差関数を最小限に抑えることによってトレーニングされます。逆に、生成ネットワークの目標は、トレーニングセットと同じ分布からサンプルを合成することで、この誤差を最大化することです。したがって、生成ネットワークと識別ネットワークは互いに敵対的に機能するため、「敵対的」という用語が生まれます。これは、一方のネットワークの利益が他方のネットワークの損失となるゼロサムゲームの一例です。これにより、識別ネットワークが生成ネットワークのトレーニングに使用できるトレーニング信号を提供できるようになり、教師なし密度モデリングの問題が教師あり学習の形式に変わります。
</p>
<h3>17.1.1 損失関数</h3>
<p>
これを正確にするために、次のような二値ターゲット変数を定義します。
\[
\begin{align}
&t=1　real\;data \tag{17.2} \\
&t=0　synthetic\;data \tag{17.3}
\end{align}
\]
識別ネットワークには、ロジスティックシグモイド活性化関数を備えた単一の出力ユニットがあり、その出力はデータベクトル \(\mathbf x\) が実データである確率を表します。
\[
P(t=1)=d(\mathbf x, \boldsymbol{\phi}) \tag{17.4}
\]
標準のクロスエントロピー誤差関数を使用して識別ネットワークを訓練します。この関数は次の形式を取ります。
\[
E(\mathbf w,\boldsymbol{\phi})=\frac{1}{N}\sum_{n=1}^N \{t_n\ln d_n+(1-t_n)\ln(1-d_n)\} \tag{17.5}
\]
ここで、\(d_n = d(\mathbf x_n, \boldsymbol{\phi})\) は入力ベクトル \(\mathbf x_n\) の識別ネットワークの出力であり、データ点の総数で正規化しています。トレーニングセットは、\(\mathbf x_n\) で示される実際のデータ例と、生成ネットワーク \(\mathbf g(\mathbf z_n, \mathbf w)\) の出力によって与えられる合成例の両方で構成されます。ここで、\(\mathbf z_n\) は潜在空間分布 \(p(\mathbf z)\) からのランダムサンプルです。実際の例では \(t_n = 1\)、合成例では \(t_n = 0\) であるため、誤差関数(17.5)は次の形式で書くことができます。
\[
\begin{align}
E_{GAN}(\mathbf w,\boldsymbol{\phi}) =& -\frac{1}{N_{real}}\sum_{n\in real} \ln d(\mathbf x_n, \boldsymbol{\phi}) \\
\\
& -\frac{1}{N_{synth}}\sum_{n\in synth} \ln(1-d(\mathbf g(\mathbf z_n,\mathbf w),\boldsymbol{\phi})) \tag{17.6}
\end{align}
\]
ここで、通常、実データポイントの数 \(N_{real}\) は、合成データポイントの数 \(N_{synth}\) に等しくなります。生成ネットワークと識別ネットワークのこの組み合わせは、バックプロパゲーションを使用して勾配を評価した確率的勾配降下法を使用して、エンドツーエンドでトレーニングできます。ただし、通常とは異なる点は、誤差が \(\boldsymbol{\phi}\) に関して最小化されるが、\(\mathbf w\) に関して最大化される敵対的トレーニングです。
</p>
<p>
この最大化は、勾配の符号を反転した標準的な勾配ベースの方法を使用して実行でき、パラメータの更新は次のようになります。
\[
\begin{align}
\Delta\boldsymbol{\phi} &= -\lambda\nabla_{\boldsymbol{\phi}} E_n(\mathbf w, \boldsymbol{\phi}) \tag{17.7} \\
\\
\Delta\mathbf w &= \lambda\nabla_{\mathbf w} E_n(\mathbf w,\boldsymbol{\phi}) \tag{17.8}
\end{align}
\]
ここで、\(E_n(\mathbf w, \boldsymbol{\phi})\) は、データポイント \(n\) , またはより一般的にはデータポイントのミニバッチに対して定義された誤差を示します。識別器は誤り率を下げるように訓練されているのに対し、生成器は誤り率を高めるように訓練されているため、(17.7)と(17.8)の2つの項の符号が異なることに注意してください。実際には、トレーニングでは、生成ネットワークのパラメーターの更新と識別ネットワークのパラメーターの更新が交互に行われます。いずれの場合も、ミニバッチを使用して勾配降下ステップを1つだけ実行し、その後、合成サンプルの新しいセットが生成されます。生成器が完全な解を見つけることに成功した場合、識別ネットワークは実際のデータと合成データの違いを見分けることができないため、常に0.5 の出力を生成します。GAN がトレーニングされると、識別ネットワークは破棄され、生成ネットワークを使用して、潜在空間からサンプリングし、トレーニングされた生成ネットワークを通じてそれらのサンプルを伝播することにより、データ空間に新しいサンプルを合成できます。無限の柔軟性を持つ生成ネットワークと識別ネットワークの場合、完全に最適化された GANはデータ分布と正確に一致する生成分布を持つことを示すことができます。GAN によって生成された合成顔画像の印象的な例を図1.3に示します。
</p>
<p>
これまで説明したGANモデルは、無条件分布p(x)からサンプルを生成します。たとえば、犬の画像でトレーニングされた場合、犬の合成画像を生成できます。また、条件付きGAN (Mirza and Osindero、2014)を作成することもできます。これは、たとえば、条件付きベクトルcがさまざまな種類の犬を表す条件付き分布p(x|c)からサンプリングします。これを行うために、生成ネットワークと識別ネットワークの両方が追加の入力としてcを受け取り、ペア{xn, cn}で構成されるラベル付き画像の例がトレーニングに使用されます。GANがトレーニングされると、cを対応するクラスベクトルに設定することで、目的のクラスからの画像を生成できます。クラスごとに個別のGANをトレーニングする場合と比較して、これには、共有された内部表現をすべてのクラスにわたって同時学習できるため、データをより効率的に使用できるという利点があります。
</p>
<h3>17.1.2. GANトレーニングの実践</h3>
<p>
GANは高品質の結果を生成できますが、敵対的学習があるため、トレーニングを成功させるのは簡単ではありません。また、標準の誤差関数の最小化とは異なり、トレーニング中に目標が上昇したり下降したりする可能性があるため、進捗状況の測定基準はありません。
</p>
<p>
発生する可能性のある課題の1つは、モード崩壊と呼ばれます。ここでは、すべての潜在変数サンプル \(\mathbf z\) が有効な出力のサブセットにマッピングされるように、生成ネットワークの重みがトレーニング中に適応されます。極端な場合には、出力は 1 つだけ、または少数の出力値 \(\mathbf x\) に対応する可能性があります。次に、識別器はこれらのインスタンスに値 0.5 を割り当て、トレーニングは終了します。たとえば、手書きの数字でトレーニングされた GANは、数字「3」の例のみを生成することを学習する可能性がありますが、識別器はこれらを数字「3」の本物の例と区別できず、生成器が全範囲の数字を生成していないことを認識できません。
</p>
<p>
GANのトレーニングの難しさについての洞察は、固定ではあるが未知のデータ分布 \(p_{Data}(\mathbf x)\) から抽出されたサンプル \(\{\mathbf x_n\}\) を含む単純な 1次元データ空間 \(\mathbf x\) を示す図17.2を考慮することで得られます。また、初期生成分布pG(x)とこの分布から抽出されたサンプルも示されています。データと生成分布は大きく異なるため、最適な識別関数d(x)は学習が簡単で、実際のサンプルまたは合成サンプルの近くでは勾配が実質的にゼロで非常に急峻な減衰を示します。GAN誤差関数(17.6)の2番目の項を考えてみましょう。d(g(z, w), φ)は、生成されたサンプルが広がる領域全体でゼロに等しいため、生成ネットワークのパラメーターwがわずかに変化しても、識別器の出力にはほとんど変化が生じないため、勾配は小さく、学習はゆっくりと進みます。
</p>
<p>
これは、図17.2に示す、識別関数の平滑化バージョン~d(x)を使用することで対処でき、これにより、生成ネットワークのトレーニングを促進するためのより強力な勾配が提供されます。最小二乗GAN (Mao et al., 2016)は、範囲(0, 1)の確率ではなく実数値の出力を生成するように識別器を変更し、クロスエントロピー誤差関数を二乗の合計誤差関数に置き換えることによって平滑化を実現します。あるいは、インスタンスノイズの手法(Sonderby et al.、2016)では、実際のデータと合成サンプルの両方にガウスノイズが追加され、これもよりスムーズな識別関数につながります。
</p>
<p>
図17.2。GANのトレーニングが難しい理由を示す概念図。固定ではあるが未知のデータ分布pData(x)と初期生成分布pG(x)を含む単純な1次元データ空間xを示しています。最適な識別関数d(x)は、トレーニングデータポイントまたは合成データポイントの近くで実質的にゼロの勾配を持ち、学習が非常に遅くなります。識別関数の平滑化バージョン~d(x)は学習の高速化につながります。
</p>
<p>
トレーニングを改善するために、GANエラー関数とトレーニング手順に対する他の多くの修正が提案されています (Mescheder、Geiger、および Nowozin、2018)。よく使用される変更の1つは、元の誤差関数の生成ネットワーク項
\[
\tag{17.9}
\]
を修正された形に置き換えることです。
\[
\tag{17.10}
\]
</p>
<p>
最初の形式は画像が偽物である確率を最小化しますが、2番目の形式は画像が本物である確率を最大化します。これら2つの形式の異なる特性は、図17.3から理解できます。生成分布pG(x)が真のデータ分布pData(x)と大きく異なる場合、量d(g(z, w)) はゼロに近く、したがって最初の形式の勾配は非常に小さくなります。2番目の形式は勾配が大きいため、トレーニングが速くなります。
</p>
<p>
図17.3。ln(d)とln(1-d)のプロットは、d = 0とd=1に近い勾配の大きく異なる挙動を示しています。
</p>
<p>
ジェネレータ分布pG(x)がデータ分布pdata(x)に近づくようにするより直接的な方法は、データ空間内で2つの分布がどれだけ離れているかを反映するように誤差基準を変更することです。これは、アースムーバーの距離としても知られるWasserstein距離を使用して測定できます。分布pG(x)を、分布pdata(x)を構築するために少しずつ輸送される土の山として想像してください。Wassersteinメトリクスは、移動した土の総量と平均移動距離を掛けたものです。Pdata(x)を構築するために土の山を再配置する多くの方法のうち、最小の平均距離を生成する方法は、メトリックの定義に使用される方法です。実際には、これを直接実装することはできず、実数値出力を持つ識別器ネットワークを使用し、重みクリッピングを使用してxに関する識別器関数の勾配∇xd(x, φ)を制限することによって近似されます。Wasserstein GANへの上昇(Arjovsky、Chintala、Bottou、2017)。改良されたアプローチは、勾配にペナルティを導入し、勾配ペナルティWasserstein GAN (Gulrajani et al., 2017) を生成することであり、その誤差関数は次のように与えられます。
\[
\tag{17.11}
\]
ここで、ηはペナルティ項の相対的な重要性を制御します。
</p>
<h2>17.2. Image GANs</h2>
<p>
GANの基本概念は、多くのアルゴリズム開発と数多くの応用を伴う膨大な研究文献を生み出しました。GANの最も広く普及し成功を収めている応用分野の1つは、画像の生成です。初期のGANモデルでは、生成器と識別器に完全に接続されたネットワークが使用されていました。ただし、畳み込みネットワークを使用すると、特に高解像度の画像の場合に多くの利点があります。識別ネットワークは画像を入力として受け取り、スカラー確率を出力として提供するため、標準の畳み込みネットワークが適切です。生成ネットワークは、低次元の潜在空間を高解像度画像にマッピングする必要があるため、図17.4に示すように、転置畳み込みに基づくネットワークが使用されます。
</p>
<p>
図17.4。ネットワークの連続するブロックの次元を拡張するための転置畳み込みの使用を示す、深層畳み込みGANのアーキテクチャ例。
</p>
<p>
高品質の画像は、低解像度から開始して生成ネットワークと識別ネットワークの両方を段階的に成長させ、トレーニングの進行に応じてますます詳細をモデル化する新しいレイヤーを連続的に追加することによって取得できます(Karras et al.、2017)。 これによりトレーニングが高速化され、サイズ4×4の画像から開始してサイズ1024×1024の高解像度画像の合成が可能になります。一部のGANアーキテクチャの規模と複雑さの例として、BigGANと呼ばれるクラス条件付き画像生成用のGANモデルを考えてみましょう。そのアーキテクチャは図17.5に示されています。
</p>
<p>
図17.5。(a)BigGANモデルの生成ネットワークのアーキテクチャ。7,000万を超えるパラメーターがあります。(b)生成ネットワーク内の各残差ブロックの詳細。8,800万のパラメータを持つ識別ネットワークは、次元数を増やすためにアップサンプリングを使用するのではなく、平均プーリング層を使用して次元数を減らすことを除いて、いくぶん類似した構造を持っています。[Based on Brock, Donahue, and Simonyan (2018),に基づく]
</p>
<h3>17.2.1. CycleGAN</h3>
<p>
多種多様なGANの例として、CycleGANと呼ばれるアーキテクチャを検討します(Zhu et al., 2017)。これは、深層学習の技術を、分類や密度推定などの従来のタスクを超えたさまざまな種類の問題を解決するためにどのように適用できるかを示しています。写真を同じ場面のモネの絵画に変える、またはその逆の問題を考えてみましょう。図17.6に、このような画像間の変換を実行することを学習したトレーニング済みCycleGANからの画像ペアの例を示します。
</p>
<p>
目的は、2つの全単射(1対1)マッピングを学習することです。1つは写真の領域Xからモネの絵画の領域Yへ、もう1つはその逆方向です。これを実現するために、CycleGANは2つの条件付き生成器gXとgYと2つの識別器dXとdYを利用します。 生成器gX(y, wX)はサンプル絵画y ∈ Yを入力として受け取り、対応する合成写真を生成します。一方、識別器dX(x, φX)は合成写真と本物の写真を区別します。同様に、生成器gY(x, wY)は写真x ∈ Xを入力として合成絵画yを生成し、識別器dY(y, φY)は合成絵画と実物を区別します。したがって、識別器dXはgXによって生成された合成写真と実際の写真の組み合わせでトレーニングされるのに対し、dYはgYによって生成された合成絵画と実際の絵画の組み合わせでトレーニングされます。
</p>
<p>
図17.6。CycleGANを使用した画像変換の例。モネの絵画からの写真風の画像の合成(上の行)と、写真からのモネの絵画風の画像の合成(下の行)を示しています。 
</p>
<p>
標準のGAN損失関数を使用してこのアーキテクチャをトレーニングすると、リアルな合成モネ絵画とリアルな合成写真を生成する方法を学習しますが、生成された絵画を対応する写真に似せるように強制したり、その逆を強制したりすることは何もありません。したがって、損失関数にサイクル整合性誤差と呼ばれる追加の項を導入します。これには2つの項が含まれており、その構造を図 17.7 に示します。
</p>
<p>
図17.7。写真xnの例についてサイクル一貫性誤差がどのように計算されるかを示す図。写真はまず生成器gYを使用して絵画ドメインにマッピングされ、次に生成されたベクトルは生成器gXを使用して写真ドメインにマッピングされます。結果として得られる写真と元のxnの間の不一致は、サイクル一貫性エラーへの寄与を定義します。同様のプロセスを使用して、gXを使用して絵画ynを写真にマッピングし、その後gYを使用して絵画に戻すことにより、絵画ynからのサイクル一貫性エラーへの寄与を計算します。
</p>
<p>
目標は、写真を絵画に変換し、その後写真に戻すときに、元の写真に近いものにすることです。これにより、生成された絵画が、写真を再構築できるように写真に関する十分な情報を確実に保持するようになります。同様に、絵画を写真に変換し、その後再び絵画に戻す場合、元の絵画に近いものにする必要があります。これをトレーニングセット内のすべての写真と絵画に適用すると、次の形式のサイクル一貫性エラーが得られます。
\[
\tag{17.12}
\]
ここで、||･||1はL1ノルムを示します。サイクル一貫性誤差は、(17.6)で定義された通常のGAN損失関数に追加されて、合計誤差関数が得られます。
\[
\tag{17.13}
\]
ここで、係数ηは、GANエラーとサイクル一貫性エラーの相対的な重要性を決定します。1つの画像と1つの絵画の誤差関数を計算する際のCycleGANを介した情報の流れを図17.8に示します。
</p>
<p>
図17.8。CycleGANを介した情報の流れ。データポイントxnとynの合計誤差は、4つの成分誤差の合計です。
</p>
<p>
GANは生成モデルとして優れたパフォーマンスを発揮できることを見てきましたが、教師なし学習を通じてデータセット内の豊富な統計構造を明らかにする表現学習にも使用できます。図17.4に示す深層畳み込みGANが寝室の画像のデータセットでトレーニングされ(Radford、Metz、および Chintala、2015)、潜在空間からのランダム サンプルがトレーニングされたネットワークを通じて伝播されると、生成された画像も予想通り寝室のように見えます。しかしさらに、潜在空間は意味論的に意味のある方法で組織化されるようになりました。たとえば、潜在空間を通る滑らかな軌跡をたどり、対応する一連の画像を生成すると、図17.9に示すように、ある画像から次の画像への滑らかな移行が得られます。
</p>
<p>
図17.9。寝室の画像でトレーニングされた深層畳み込みGANによって生成されたサンプル。各行は、ランダムに生成された位置間の潜在空間をスムーズにウォークすることによって生成されます。滑らかな遷移が見られ、各画像はおそらく寝室のように見えます。たとえば、下の行では、壁にあるテレビが徐々に窓に変わっていくのがわかります。
</p>
<p>
さらに、意味的に意味のある変換に対応する潜在空間内の方向を識別することが可能です。たとえば、顔の場合、ある方向は顔の向きの変化に対応し、他の方向は照明の変化や顔が笑っているかどうかの程度に対応している可能性があります。これらは解きほぐされた表現と呼ばれ、指定されたプロパティを持つ新しいイメージを合成できるようになります。図17.10は、顔画像でトレーニングされたGANの例で、性別や眼鏡の有無などの意味属性が潜在空間内の特定の方向に対応していることを示しています。
</p>
<p>
図17.10。訓練されたGANの潜在空間におけるベクトル演算の例。3つの列のそれぞれで、これらの画像を生成した潜在空間ベクトルが平均化され、結果の平均ベクトルにベクトル演算が適用されて、右側の3×3配列の中央の画像に対応する新しいベクトルが作成されます。このベクトルにノイズを追加すると、さらに8つのサンプル画像が生成されます。下の行の4つの画像は、同じ演算をデータ空間に直接適用すると、位置ずれが原因で画像がぼやけてしまうだけであることを示しています。
</p>
<h2>演習問題</h2>
<h3>17.1(★★★)</h3>
<p>
GAN誤差関数(17.6)には、十分に柔軟なニューラルネットワークが与えられた場合、生成器の分布が真のデータ分布と一致するときに定常点が得られるという特性を持たせたいと考えています。この演習では、生成ネットワークと識別ネットワークにそれぞれ対応する確率分布q(x)の全空間と関数d(x)の全空間にわたって最適化することにより、無限の柔軟性を備えたネットワークモデルのこの結果を証明します。具体的には、識別モデルが内部ループで最適化され、生成モデルに有効な外部ループ誤差関数が生じると仮定します。まず、無限数のデータサンプルの制限内で、GAN誤差関数(17.6)が次の形式で書き換えられることを示せ。
\[
\tag{17.14}
\]
ここで、Pdata(X)は実データポイントの固定分布です。ここで、すべての関数d(x)に対する変分最適化を考えてみましょう。固定生成ネットワークの場合、Eを最小化する識別子d(x)の解は次の式で与えられることを示せ。
\[
\tag{17.15}
\]
したがって、誤差関数Eが生成ネットワークpG(x)の関数として次の形式で記述できることを示せ。
\[
\tag{17.16}
\]
これが次の形式で書き換えられることを示せ。
\[
\tag{17.17}
\]
ここで、Kullback-LeiblerダイバージェンスKL(p||q)は(2.100)によって定義されます。最後に、すべてのxについてp(x) = q(x)である場合に限り、KL(pl|q) ≥ 0が等しいという特性を使用して、pG(x) = Pdata(x)のときにC(pG) の最小値が発生することを示せ。(17.17)の2つのKullback-Leiblerダイバージェンス項の合計は、PdataとpGの間のJensen-Shannonダイバージェンスとして知られていることに注意してください。Kullback-Leiblerダイバージェンスと同様、これは2つの分布が等しい場合にのみ消滅する非負の量ですが、KLダイバージェンスとは異なり、2つの分布に関して対称です。
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
    </body>
</html>
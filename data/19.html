<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>19章</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
            .margin-large
            {
                margin-left: 30px;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .two-columns {
            display: flex;
            flex-direction: row;
            gap: 20px; /* 列間のスペース */
        }
        .column {
            flex: 1; /* 各列が均等に幅を取る */
        }
    </style>
<style>
.three-columns {
  display: flex;
  gap: 10px; /* 列間の余白を設定 */
}
.column {
  flex: 1; /* 各列の幅を均等にする */
  padding: 10px; /* 内側の余白を設定 */
}
</style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 0px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
            ol
            {
                margin-left: 30px;
            }
            ul
            {
                margin-left: 30px;
            }
    </style>
    <style>
        .thin-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 1px;
            background-color: gray;
        }

        .thick-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 2px;
            background-color: black;
        }
    </style>
    <style>
        .highlight {
            color: red; /* 好きな色に変更してください */
        }
    </style>
    </head>
    <body>
        <h1><center>19章 オートエンコーダー</center></h1>
<p>
深層学習の中心的な目標は、1つ以上の後続のアプリケーションに役立つデータ表現を発見することです。内部表現を学習するための確立されたアプローチの1つは、自動連想ニューラルネットワークまたはオートエンコーダーと呼ばれます。これは、入力と同じ数の出力ユニットを持ち、入力 \(\mathbf x\) に近い出力 \(\mathbf y\) を生成するようにトレーニングされたニューラルネットワークで構成されます。トレーニングが完了すると、ニューラルネットワーク内の内部層は、新しい入力ごとに \(\mathbf z(\mathbf x)\) という表現を与えます。このようなネットワークは2つの部分から構成されると考えることができます。1つ目は入力 \(\mathbf x\) を隠し表現 \(\mathbf z(\mathbf x)\) にマップするエンコーダーで、2つ目は隠れ表現を出力 \(\mathbf y(\mathbf z)\) にマップするデコーダーです。
</p>
<p>
オートエンコーダが自明ではない解を見つけるには、何らかの形式の制約を導入する必要があります。そうしないと、ネットワークは入力値を出力にコピーするだけで済みます。この制約は、たとえば \(\mathbf x\) の次元に対して \(\mathbf z\) の次元を制限することによって、または \(\mathbf z\) がスパース表現を持つことを要求することによって達成される可能性があります。あるいは、ネットワークが加法性ノイズや欠損値などの入力ベクトルの破損を元に戻すことを学習するようにトレーニング プロセスを変更することで、ネットワークに非自明な解決策を発見させることもできます。このような種類の制約により、ネットワークはデータ内の興味深い構造を発見し、良好なトレーニングパフォーマンスを達成することができます。
</p>
<p>
この章では、決定論的オートエンコーダから始めて、その後、エンコーダ分布 \(p(\mathbf z|\mathbf x)\) とデコーダ分布 \(p(\mathbf y|\mathbf z)\) を学習する確率的モデルに一般化します。これらの確率モデルは変分オートエンコーダーとして知られており、非線形潜在変数モデルを学習するための4つのアプローチのうちの3番目を表します。
</p>
<h2>19.1 決定論的オートエンコーダー</h2>
<p>
主成分分析(PCA: Principal Component Analysis)を研究したときに、単純な形式のオートエンコーダーに出会いました。これは、入力ベクトルを低次元多様体に線形変換するモデルであり、結果として得られる射影は、再び線形変換を通じて元のデータ空間に近似的に再構築できます。ニューラルネットワークの非線形性を利用して、潜在多様体がデータ空間の線形部分空間ではなくなる非線形 PCA の形式を定義できます。これは、入力と同じ数の出力を持つネットワークを使用し、トレーニングデータのセットに関する入力と出力の間の再構成誤差のある程度の尺度を最小限に抑えるように重みを最適化することによって達成されます。
</p>
<p>
シンプルなオートエンコーダは、潜在空間で意味的に意味のある表現を提供せず、データ分布から新しいサンプルを直接生成できないため、現代の深層学習で直接使用されることはほとんどありません。ただし、変分オートエンコーダーなどのより強力な深層生成モデルの一部には重要な概念的基盤が提供されます。
</p>
<h3>19.1.1 線形オートエンコーダー</h3>
<p>
まず、図19.1に示す形式の多層パーセプトロンを考えます。この多層パーセプトロンは、D 個の入力、D 個の出力ユニット、および M 個の隠れユニットを持ち、M < D です。ネットワークの学習に使用されるターゲットは単に入力ベクトルそのものであるため、ネットワークは次のことを試みます。各入力ベクトルをそれ自体にマッピングします。このようなネットワークは、自動連想マッピングを形成するといわれます。隠れユニットの数は入力の数よりも少ないため、すべての入力ベクトルを完全に再構成することは一般に不可能です。したがって、入力ベクトルとその再構成の間の不一致の程度を捉える誤差関数を最小化することによって、ネットワークパラメーター \(\mathbf w\)を決定します。特に、次の形式の二乗和誤差を選択します。
\[
E(\mathbf w)=\frac{1}{2}\sum_{n=1}^N||\mathbf y(\mathbf x_n,\mathbf w)-\mathbf x_n||^2 \tag{19.1}
\]
</p>
<center><img src="images/fig19_1.png"></center>
<p class="margin-large">
図19.1　2つの重み層を持つオートエンコーダー・ニューラルネットワーク。このようなネットワークは、二乗和誤差を最小限に抑えることで入力ベクトルをそれ自体にマッピングするように訓練されています。隠れ層に非線形ユニットがある場合でも、このようなネットワークは線形主成分分析と同等です。わかりやすくするために、バイアスパラメーターを表すリンクは省略されています。
</p>
<p>
隠れユニットが線形活性化関数を持っている場合、誤差関数には一意のグローバル最小値があり、この最小値でネットワークは、データの M 次元の部分空間への射影を実行します(BourlardとKamp、1988; Baldi と Hornik、1989)。したがって、図19.1 の隠れユニットにつながる重みのベクトルは、主部分空間にわたる基底関数セットを形成します。ただし、これらのベクトルは直交または正規化する必要がないことに注意してください。PCA とニューラルネットワークはどちらも線形次元削減に依存しており、同じ二乗和誤差関数を最小化するため、この結果は驚くべきことではありません。
</p>
<p>
線形多様体の制限は、図 19.1のネットワーク内の隠れユニットに非線形活性化関数を使用することで克服できると考えられるかもしれません。ただし、非線形の隠れ単位を使用した場合でも、最小誤差の解は主成分部分空間への射影によって再び得られます(Bourlard および Kamp、1988)。したがって、次元削減を実行するために2層ニューラル ネットワークを使用する利点はありません。特異値分解(SVD: Singular Value Decomposition)に基づく PCA の標準技術は、有限時間内に正しい解を与えることが保証されており、対応する正規直交固有ベクトルを含む固有値の順序付きセットも生成します。
</p>
<h3>19.1.2 ディープ・オートエンコーダー</h3>
<p>
ただし、ネットワークに追加の非線形層が含まれる場合、状況は異なります。図19.2に示す4層の自動連想ネットワークを考えてみましょう。繰り返しますが、出力ユニットは線形であり、2番目の層の M ユニットも線形にすることができます。ただし、第1層と第3層はシグモイド非線形活性化関数を持ちます。ネットワークは、誤差関数(19.1)を最小化することによって再度トレーニングされます。図19.2に示すように、このネットワークは2つの連続する機能マッピング \(\mathbf F_1\) および \(\mathbf F_2\) として見ることができます。 最初のマッピング \(\mathbf F_1\) は、元の D 次元データを、第2層のユニットのアクティブ化によって定義される M 次元部分空間 S に投影します。非線形ユニットの最初の層のため、このマッピングは非常に一般的であり、線形であることに限定されません。同様に、ネットワークの後半では、M 次元の隠れ空間から元の D 次元の入力空間への任意の関数マッピングを定義します。図19.3の D = 3 および M = 2 に示されているように、これは単純な幾何学的解釈になります。
</p>
<center><img src="images/fig19_2.png"></center>
<p class="margin-large">
図19.2　非線形ユニットの追加の隠れ層を追加すると、非線形次元削減を実行できる自動連想ネットワークが生成されます。
</p>
<center><img src="images/fig19_3.png"></center>
<p class="margin-large">
図19.3　第2層のD = 3入力および M = 2 ユニットを持つモデルに対して、図19.2のネットワークによって実行されたマッピングの幾何学的解釈。潜在空間からの関数F2は、多様体 S が高次元データ空間内に埋め込まれる方法を定義します。\(\mathbf F_2\) は非線形になる可能性があるため、図に示すように、S の埋め込みは非平面になる可能性があります。次に、関数 \(\mathbf F_1\) は元の D 次元データ空間から M 次元の潜在空間への射影を定義します。
</p>
<p>
このようなネットワークは、非線形形式の PCA を効果的に実行します。特殊なケースとして標準 PCA が含まれていますが、線形変換に限定されないという利点があります。ただし、誤差関数(19.1)はネットワークパラメーターの二次関数ではなくなったため、ネットワークのトレーニングには非線形最適化が必要になります。計算負荷の高い非線形最適化手法を使用する必要があり、誤差関数の次善の極小値が見つかるリスクがあります。また、ネットワークをトレーニングする前に、部分空間の次元を指定する必要があります。
</p>
<h3>19.1.3. スパースなオートエンコーダー</h3>
<p>
ネットワーク内の隠れ層の1つでノードの数を制限する代わりに、内部表現を制約する別の方法は、正則化子を使用してスパース表現を促進し、実効次元の低下につながることです。
</p>
<p>
簡単な選択は L1 正則化です。これにより、まばらさが促進され、次の形式の正則化された誤差関数が得られます。
\[
\tilde{E}(\mathbf w)=E(\mathbf w)+\lambda\sum_{k=1}^K |z_k| \tag{19.2}
\]
ここで、\(E(\mathbf w)\) は非正則化誤差であり、kの合計が隠れ層の1つのすべてのユニットの活性化値として採用されます。通常、正則化はネットワークのパラメータに適用されますが、ここではユニットのアクティベーションに使用されていることに注意してください。勾配降下トレーニングに必要な導関数は、通常どおり自動微分を使用して評価できます。
</p>
<h3>19.1.4 デノイズ・オートエンコーダー</h3>
<p>
モデルが単純に恒等マッピングを学習することを避けるために、単純なオートエンコーダーで潜在空間層の次元を制約することが重要であることがわかりました。モデルにデータ内の興味深い内部構造の発見を強制する別のアプローチは、ノイズ除去オートエンコーダーを使用することです(Vincentら, 2008)。このアイデアは、各入力ベクトル \(x_i\) を取得し、それをノイズで破損して修正ベクトル \(\tilde{\mathbf x}_i\) を生成し、それをオートエンコーダーに入力して出力 \(\mathbf y(\tilde{\mathbf x}_n, \mathbf w)\) を生成するというものです。ネットワークは、次の式で与えられる二乗和などの誤差関数を最小化することによって、元のノイズのない入力ベクトルを再構築するようにトレーニングされます。
\[
E(\mathbf w)=\sum_{n=1}^N||\mathbf y(\tilde{\mathbf x}_n,\mathbf w)-\mathbf x_n||^2 \tag{19.3}
\]
</p>
<p>
ノイズの1つの形式には、ランダムに選択された入力変数のサブセットをゼロに設定することが含まれます。このような入力の小数 \(\nu\) はノイズレベルを表し、\(0\leq \nu\le 1\) の範囲内にあります。別のアプローチは、独立したゼロ平均ガウスノイズをすべての入力変数に追加することです。この場合、ノイズのスケールはガウスの分散によって設定されます。入力データのノイズ除去を学習することで、ネットワークはそのデータの構造の側面を学習することになります。たとえば、データが画像で構成されている場合、近くのピクセル値に強い相関があることを学習することで、ノイズで破損したピクセルを補正できます。
</p>
<p>
より正式には、ノイズ除去オートエンコーダーのトレーニングは、スコアが \(s(\mathbf x) = ∇_{\mathbf x} \ln p(\mathbf x)\) によって定義されるスコア マッチング (Vincent、2011) に関連しています。 この関係についての直観の一部を図 19.4 に示します。 オートエンコーダは、歪みベクトル \(\tilde{\mathbf x}_n－\mathbf x_n\) を反転することを学習し、したがって多様体、つまりデータ密度の高い領域を指すデータ空間内の各点のベクトルを学習します。スコアベクトル \(∇\ln p(\mathbf x)\) も同様に、データ密度の高い領域を指すベクトルです。 ノイズで破損した入力からノイズを除去することも学習する拡散モデルについて説明するときに、スコア マッチングとノイズ除去の関係をさらに詳しく調べます。
</p>
<center><img src="images/fig19_4.png"></center>
<p class="margin-large">
図19.4　ノイズ除去オートエンコーダーでは、データ空間内の低次元多様体上に存在すると想定されるデータ点が加法性ノイズによって破損します。オートエンコーダーは、破損したデータポイントを元の値にマップして戻すことを学習するため、多様体を指すデータ空間内の各ポイントのベクトルを学習します。
</p>
<h3>19.1.5 マスクされたオートエンコーダー</h3>
<p>
BERTなどの変換モデルは、入力のランダムなサブセットをマスクすることで自己教師あり学習を通じて自然言語の豊富な内部表現を学習できることがわかりました。同様のアプローチを自然画像に適用できるかどうか疑問に思うのは自然なことです。マスクされたオートエンコーダ(Heら, 2021)では、ノイズ除去オートエンコーダと同様に、入力として画像の破損したバージョンが与えられると、ディープネットワークを使用して画像を再構築します。ただし、この場合、破損の形式は、入力画像の一部がマスクされるか、ドロップアウトされることです。この手法は通常、ビジョントランスフォーマーアーキテクチャと組み合わせて使用されます。この場合、ランダムに選択された入力パッチトークンのサブセットのみをエンコーダーに渡すことで、入力のマスキング部分を簡単に実装できます。全体的なアルゴリズムを図19.5にまとめます。
</p>
<center><img src="images/fig19_5.png"></center>
<p class="margin-large">
図19.5　トレーニングフェーズ中のマスクされたオートエンコーダのアーキテクチャ。損失はマスクされたパッチにのみ適用されるため、ターゲットは入力の補数であることに注意してください。トレーニング後、デコーダーは破棄され、エンコーダーは、ダウンストリームタスクで使用するために画像を内部表現にマッピングするために使用されます。
</p>
<p>
言語と比較して、画像は局所的な相関関係が強く、冗長性がはるかに高くなります。文から1つの単語を省略すると、あいまいさが大幅に増加する可能性がありますが、画像からランダムなパッチを削除しても、通常、画像の意味論にはほとんど影響がありません。当然のことながら、入力イメージの比較的高い割合(通常はBERTの15%のマスキングと比較して75%)がマスクされると、最良の内部表現が学習されます。BERTでは、マスクされた入力は固定マスクトークンに置き換えられますが、マスクされたオートエンコーダーでは、マスクされたパッチは単純に省略されます。入力パッチの大部分を省略することで、特にトランスフォーマーのトレーニングインスタンスに必要な計算が入力シーケンスの長さに応じてスケーリングが不十分なため、大幅な計算を節約できます。そのため、マスクされたオートエンコーダーは、大規模なトランスフォーマーエンコーダーの事前トレーニングに適した選択肢になります。
</p>
<p>
デコーダー層はトランスフォーマーでもあるため、元の画像の次元で機能する必要があります。トランスフォーマーの出力は入力と同じ次元を持つため、エンコーダーの出力とデコーダーの入力の間で画像の次元を復元する必要があります。これは、位置エンコード情報によって強化された各パッチトークンを使用して、固定マスクトークンベクトルで表されるマスクされたパッチを復元することによって実現されます。デコーダ表現の次元がはるかに高いため、デコーダトランスフォーマの学習可能なパラメータはエンコーダよりもはるかに少なくなります。デコーダの出力の後には、出力表現をピクセル値の空間にマッピングする学習可能な線形層が続きます。トレーニング誤差関数は、各画像の欠落パッチを平均した単純な平均二乗誤差です。 トレーニングされたマスクオートエンコーダーによって再構成された画像の例を図19.6に示します。これは、トレーニングされたオートエンコーダーが意味的に妥当な再構成を生成する能力を示しています。ただし、最終的な目標は、後続のダウンストリームタスクに役立つ内部表現を学習することです。この場合、デコーダーは破棄され、エンコーダーはマスキングなしで、必要なアプリケーションに合わせて微調整された出力レイヤーの新しいセットを使用して画像全体に適用されます。このアルゴリズムは当初画像データ用に設計されましたが、理論的にはあらゆるモダリティに適用できることにも注意してください。
</p>
<center><img src="images/fig19_6.png"></center>
<p class="margin-large">
図19.6　トレーニングされたマスクオートエンコーダを使用して再構成された画像の4つの例。入力パッチの80%がマスクされています。いずれの場合も、マスクされた画像が左側、再構成された画像が中央、元の画像が右側にあります。[He et al. (2021)]
</p>
<h2>19.2 変分オートエンコーダー</h2>
<p>
潜在変数モデルの尤度関数が次のように与えられることをすでに見てきました。
\[
p(\mathbf x|\mathbf w)=\int p(\mathbf x|\mathbf z,\mathbf w)p(\mathbf z)d\mathbf z \tag{19.4}
\]
\(p(\mathbf x|\mathbf z, \mathbf w)\) がディープニューラルネットワークによって定義される場合、\(\mathbf z\) に関する積分は解析的に評価できないため、処理が困難です。変分オートエンコーダあるいは VAE(Kingma and Welling, 2013; Rezende, Mohamed, and Wierstra, 2014; Doersch, 2016; Kingma and Welling, 2019)は、代わりに、モデルをトレーニングするときにこれの近似値を使用して機能します。VAE には3つの重要なアイデアがあります: (i)EM アルゴリズムと密接な関係をもたらす、尤度関数を近似するためのエビデンス下界(ELBO: Evicence Lower Bound)の使用、(ii)2番目のモデルであるエンコーダーを使用した償却推論ネットワークは、各データポイントの事後分布を正確に評価するのではなく、Eステップで潜在変数の事後分布を近似するために使用され、(iii)再パラメータ化トリックを使用してエンコーダモデルのトレーニングを扱いやすくします。
</p>
<p>
ディープニューラルネットワーク \(\mathbf g(\mathbf z, \mathbf w)\) の出力によって制御される D 次元データ変数 \(\mathbf x\) にわたる条件付き分布 \(p(\mathbf x|\mathbf z, \mathbf w)\) を持つ生成モデルを考えてみましょう。たとえば、\(\mathbf g(\mathbf z, \mathbf w)\) はガウス条件付き分布の平均を表す場合があります。また、平均ゼロの単位分散ガウス分布によって与えられる M 次元の潜在変数 \(\mathbf z\) にわたる分布を考えてみましょう。
\[
p(\mathbf z)=\mathcal N(\mathbf z|\mathbf 0,\mathbf I) \tag{19.5}
\]
</p>
<p>
VAE 近似を導出するには、まず、潜在変数 \(\mathbf z\) で記述される空間上の任意の確率分布 \(q(\mathbf z)\) に対して、次の関係が成り立つことを思い出してください。
\[
\ln p(\mathbf x|\mathbf w)=\mathcal L(\mathbf w)+KL\left(q(\mathbf z)||p(\mathbf z|\mathbf x,\mathbf w)\right) \tag{19.6}
\]
ここで、\(\mathcal L\) はエビデンス下界、つまり ELBO であり、変分下界とも呼ばれ、次の式で与えられます。
\[
\mathcal L(\mathbf w)=\int q(\mathbf z)\ln\left\{\frac{p(\mathbf x|\mathbf z,\mathbf w)p(\mathbf z)}{q(\mathbf z)}\right\}d\mathbf z \tag{19.7}
\]
そしてカルバック・ライブラーダイバージェンス KL(･||･) は次のように定義されます。
\[
KL\left(q(\mathbf z)||p(\mathbf z|\mathbf x,\mathbf w)\right)=-\int q(\mathbf z)\ln\left\{\frac{p(\mathbf z|\mathbf x,\mathbf w)}{q(\mathbf z)}\right\} \tag{19.8}
\]
</p>
<p>
カルバック・ライブラーダイバージェンスは KL(q||p) ≥ 0 を満たすため、次のようになります。
\[
\ln p(\mathbf x|\mathbf w)\geq\mathcal L \tag{19.9}
\]
したがって、\(\mathcal L\) は \(\ln p(\mathbf x|\mathbf w)\) の下界です。対数尤度 \(\ln p(\mathbf x|\mathbf w)\) は扱いにくいですが、モンテカルロ推定を使用して下界を評価する方法を見てみましょう。したがって、真の対数尤度の近似値が得られます。
</p>
<p>
次に、モデル分布 \(p(\mathbf x)\) から独立して抽出されると想定される一連のトレーニングデータ点 \(\mathcal D = \{\mathbf x_1,\cdots, \mathbf x_N\}\) について考えます。 このデータセットの対数尤度関数は次のように与えられます。
\[
\ln p(\mathcal D|\mathbf w)=\sum_{n=1}^N\mathcal L_n+\sum_{n=1}^N KL(q_n(\mathbf z_n)||p(\mathbf z_n|\mathbf x_n,\mathbf w)) \tag{19.10}
\]
ここで
\[
\mathcal L_n=\int q_n(\mathbf z_n)\ln\left\{\frac{p(\mathbf x_n|\mathbf z_n,\mathbf w)p(\mathbf z_n)}{q_n(\mathbf z_n)}\right\}d\mathbf z_n \tag{19.11}
\]
</p>
<p>
混合モデルや確率的 PCA モデルで見たように、これにより、各データ ベクトル \(\mathbf x\) に対応する別個の潜在変数 \(\mathbf z\) が導入されることに注意してください。したがって、各潜在変数は独自の独立した分布 \(q_n(\mathbf z_n)\) を持ち、それぞれを個別に最適化できます。
</p>
<p>
(19.10)は分布 \(q_n(\mathbf z)\) の任意の選択に対して成り立つため、限界 \(\mathcal L_n\) を最大化する分布、または同等にカルバックライブラーダイバージェンス \(KL(q_n(\mathbf z_n)||p(\mathbf z_n) |\mathbf x_n,\mathbf w))\) を最小化する分布を選択できます。以前に検討した単純なガウス混合モデルと確率的 PCA  モデルの場合、EM アルゴリズムの E ステップでこれらの事後分布を正確に評価することができました。これは、各 \(q_n(\mathbf z_n)\) を対応する事後分布 \(p(\mathbf z_n|\mathbf x_n, \mathbf w)\) に等しく設定することに相当します。これにより、カルバック・ライブラーダイバージェンスがゼロになるため、下界は真の対数尤度に等しくなります。事後分布の解釈は、敵対的生成ネットワークのコンテキストで以前に紹介した簡単な例を使用して図19.7に示されています。
</p>
<center><img src="images/fig19_7.png"></center>
<p class="margin-large">
図19.7　図16.13に示したものと同じモデルの事後分布の評価。(b)の右端のプロットに示されている周辺分布p(x)はバナナの形状をしており、特定のデータ点x*は中央よりも形状の角に近くなります。その結果、(a)に示す事後分布 \(p(\mathbf z|\mathbf x^*)\)は、事前分布 \(p(\mathbf z)\) が単峰性であるにもかかわらず、双峰性です[Prince (2020)に基づく]
</p>
<p>
\(\mathbf z_n\) の正確な事後分布は、ベイズの定理から次のように与えられます。
\[
p(\mathbf z_n|\mathbf x_n,\mathbf w)=\frac{p(\mathbf x_n|\mathbf z_n,\mathbf w)p(\mathbf z_n)}{p(\mathbf x_n|\mathbf w)} \tag{19.12}
\]
</p>
<p>
分子は、深い生成モデルの評価が簡単です。ただし、分母は尤度関数によって与えられることがわかりますが、これはすでに述べたように扱いが困難です。したがって、事後分布の近似値を見つける必要があります。原理的には、分布 \(q_n(\mathbf z_n)\) ごとに個別のパラメーター化されたモデルを検討し、各モデルを数値的に最適化することができますが、これは、特に大規模なデータセットの場合、計算コストが非常に高くつき、さらに再実行する必要があります。\(\mathbf w\) を更新するたびに分布を評価します。代わりに、2番目のニューラルネットワークの導入に基づいた、別のより効率的な近似フレームワークに目を向けます。
</p>
<h3>19.2.1 償却推論</h3>
<p>
変分オートエンコーダーでは、各データ点xnの個別の事後分布 \(p(\mathbf z_n|\mathbf x_n, \mathbf w)\) を個別に評価しようとするのではなく、エンコーダーネットワークと呼ばれる単一のニューラルネットワークをトレーニングして、これらすべての分布を近似します。この手法は償却推論と呼ばれ、xを条件とする単一の分布 \(q(\mathbf z|\mathbf x, \phi)\) を生成するエンコーダが必要です。ここで、\(\boldsymbol{\phi}\) はネットワークのパラメータを表します。エビデンス下界によって与えられる目的関数は、\(\mathbf w\) だけでなく \(\boldsymbol{\phi}\) にも依存するようになり、勾配ベースの最適化手法を使用して、パラメータの両方のセットに関して一緒に上限を最大化します。
</p>
<p>
したがって、VAE は、独立したパラメーターを持ちながら同時トレーニングされる2つのニューラルネットワークで構成されます。データベクトルを取得して潜在空間にマッピングするエンコーダーネットワークと、潜在空間ベクトルを取得してデータにマッピングし直す元のネットワークです。したがって、これをデコーダネットワークとして解釈できます。これは単純なニューラルネットワークオートエンコーダーモデルと似ていますが、潜在空間全体にわたる確率分布を定義する点が異なります。エンコーダーがベイズの定理に従ってデコーダーの近似確率逆関数を計算することがわかります。
</p>
<p>
エンコーダの一般的な選択は、対角共分散行列を含むガウス分布です。その平均パラメータと分散パラメータ \(μ_j\) と \(σ_j^2\) は、\(\mathbf x\) を入力として受け取るニューラルネットワークの出力によって与えられます。
\[
q(\mathbf z|\mathbf x,\boldsymbol{\phi})=\prod_{j=1}^M \mathcal N\left(\mathbf z_j|\mu_j(\mathbf x,\boldsymbol{\phi}),\sigma_j^2(\mathbf x,\boldsymbol{\phi})\right) \tag{19.13}
\]
平均 \(μ_j(\mathbf x, \mathbf \phi)\) は範囲 (－∞, ∞) 内にあるため、対応する出力ユニット活性化関数は線形になることができますが、分散 \(σ_j^2(\mathbf x,\boldsymbol{\phi})\) は非負でなければならないことに注意してください。関連する出力ユニットは通常、活性化関数として exp(・) を使用します。
</p>
<p>
目標は、勾配ベースの最適化を使用して、通常はミニバッチに基づく確率的勾配降下法を使用して、パラメーター \(\boldsymbol{\phi}\) と \(\mathbf w\) の両方のセットに関する境界を最大化することです。パラメータを同時に最適化しますが、概念的には、図19.8に示すように、EM アルゴリズムの精神に基づいて、\(\boldsymbol{\phi}\) の最適化と \(\mathbf w\) の最適化を交互に行うことを想像できます。
</p>
<center><img src="images/fig19_8.png"></center>
<p class="margin-large">
図19.8　ELBO(エビデンス下界)の最適化の図。(a)デコーダネットワークパラメータ \(\mathbf w\) の与えられた値 \(\mathbf w_0\) に対して、エンコーダネットワークのパラメータ \(\boldsymbol{\phi}\) を最適化することで境界を増やすことができます。(b)与えられた \(\boldsymbol{\phi}\) の値に対して、\(\mathbf w\) を最適化することで ELBO 関数の値を増やすことができます。エンコーダネットワークは通常、真の事後分布と正確に一致できないため、青い曲線で示される ELBO 関数は、常に赤で示される遅れ尤度関数よりも若干下に位置することに注意してください。
</p>
<p>
EM と比較した主な違いは、\(\mathbf w\) の値が指定された場合、エンコーダーのパラメーター \(\boldsymbol{\phi}\) に関して最適化しても、一般にカルバック・ライブラーダイバージェンスがゼロにならないことです。これは、エンコーダーネットワークが、事後潜在分布であるため、下界と真の対数尤度の間には残留ギャップが存在します。エンコーダは非常に柔軟ですが、ディープニューラルネットワークに基づいているため、真の事後分布を正確にモデル化することは期待できません。その理由は、(i)真の条件付き事後分布は因数分解されたガウス分布ではない、(ii)たとえ大きなガウスであってもニューラルネットワークには柔軟性が限られており、(iii)トレーニングプロセスは近似的な最適化にすぎません。EM アルゴリズムと ELBO 最適化の関係を図19.9にまとめます。
</p>
<center><img src="images/fig19_9.png"></center>
<p class="margin-large">
図19.9　VAE における EM アルゴリズムと ELBO 最適化の比較。(a)EM アルゴリズムでは、E ステップでの変分事後分布の更新と M ステップでのモデルパラメーターの更新を交互に行います。Eステップが正確である場合、下界と対数尤度の間のギャップは、各Eステップ後にゼロに減少します。(b)VAE では、エンコーダネットワークパラメータ \(\boldsymbol{\phi}\)(E ステップに類似)とデコーダネットワークパラメータ \(\mathbf w\)(M ステップに類似)の同時最適化を実行します。
</p>
<h3>19.2.2 再パラメータ化トリック</h3>
<p>
残念ながら、現状では、下界(19.11)は依然として計算が困難です。これは、潜在変数{\(\mathbf z_n\)}の積分が関係しており、デコーダーネットワークのせいで被積分関数が潜在変数に複雑に依存しているためです。データ点 \(\mathbf x\) については、下界への寄与を次の形式で書くことができます。
\[
\begin{align}
\mathcal L_n(\mathbf w,\boldsymbol{\phi})=\int q(\mathbf z_n|\mathbf x_n,\boldsymbol{\phi})\ln\left\{\frac{p(\mathbf x_n|\mathbf z_n,\mathbf w)p(\mathbf z_n)}{q(\mathbf z_n|\mathbf x_n,\boldsymbol{\phi})}\right\}d\mathbf z_n \\
=\int q(\mathbf z_n|\mathbf x_n,\boldsymbol{\phi})\ln p(\mathbf x_n|\mathbf z_n,\mathbf w)d\mathbf z_n-KL\left(q(\mathbf z_n|\mathbf x_n,\boldsymbol{\phi})||p(\mathbf z_n)\right) \tag{19.14}
\end{align}
\]
</p>
<p>
右辺の第2項は、演習2.27の2つのガウス分布間のカルバック・ライブラーダイバージェンスであり、分析的に評価できます。
\[
KL\left(q(\mathbf z_n|\mathbf x_n,\boldsymbol{\phi})||p(\mathbf z_n)\right)=\frac{1}{2}\sum_{j=1}^M \{1+\ln\sigma_j^2(\mathbf x_n)-\mu_j^2(\mathbf x_n)-\sigma_j^2(\mathbf x_n)\} \tag{19.15}
\]
</p>
<p>
(19.14)の最初の項については、単純なモンテカルロ推定器を使用して、\(\mathbf z\) に関する積分の近似を試みることができます。
\[
\int q(\mathbf z_n|\mathbf x_n,\boldsymbol{\phi})\ln p(\mathbf x_n|\mathbf z_n,\mathbf w)d\mathbf z_n\simeq \frac{1}{L}\sum_{l=1}^L \ln p\left(\mathbf x_n|\mathbf z_n^{(l)},\mathbf w\right) \tag{19.16}
\]
ここで、{\(\mathbf z_n^{(l)}\)} はエンコーダ分布 \(q(\mathbf z_n|\mathbf x_n, \boldsymbol{\phi})\) から抽出されたサンプルです。これは \(\mathbf w\) に関して簡単に微分できますが、\(\boldsymbol{\phi}\) に関する勾配には問題があります。なぜなら、\(\boldsymbol{\phi}\) を変更すると、サンプルが抽出される分布 \(q(\mathbf z_n|\mathbf x_n, \boldsymbol{\phi})\) が変化するためです。ただし、これらのサンプルは固定値であるため、\(\boldsymbol{\phi}\) に関するこれらのサンプルの導関数を取得する方法がありません。概念的には、図19.10に示すように、\(\mathbf z_n\) を特定のサンプル値に固定するプロセスは、エンコーダネットワークへの誤差信号の逆伝播をブロックするものと考えることができます。
</p>
<center><img src="images/fig19_10.png"></center>
<p class="margin-large">
図19.10　潜在変数zをサンプル値に固定することによって ELBO が推定される場合、これによりエンコーダネットワークへの誤差信号の逆伝播がブロックされます。
</p>
<p>
これは、\(\boldsymbol{\phi}\) に関する導関数を明示的に計算できるようにモンテカルロサンプリング手順を再定式化する再パラメータ化トリックを利用することで解決できます。まず、ε がゼロ平均と単位分散を持つガウス確率変数である場合、量は
\[
z=\sigma\varepsilon+\mu \tag{19.17}
\]
平均 μ と分散 \(σ^2\) のガウス分布になります。これを(19.16)のサンプルに適用します。ここで、\(μ\) と \(σ\) はエンコーダネットワークの出力 \(μ_j(\mathbf x_n, \boldsymbol{\phi})\) と \(σ_j^2(\mathbf x_n, \boldsymbol{\phi})\) によって定義され、分布(19.13)の平均と分散を表します。\(\mathbf z_n\) のサンプルを直接抽出する代わりに、ε のサンプルを抽出し、(19.17)を使用して \(\mathbf z_n\) の対応するサンプルを評価します。
\[
z_{nj}^{(l)}=\mu_j(x_n,\phi)\varepsilon_{nj}^{(l)}+\sigma_j^2(x_n,\phi) \tag{19.18}
\]
ここで、\(l = 1, ..., L\) はサンプルのインデックスです。これにより、図19.11に示すように、\(\boldsymbol{\phi}\) への依存性が明確になり、\(\boldsymbol{\phi}\) に関する勾配を評価できるようになります。再パラメータ化のトリックは他の分布にも拡張できますが、連続変数に限定されます。 再パラメータ化の手法を使わずに勾配を直接評価する手法もありますが(Williams、1992)、これらの推定量は分散が大きいため、再パラメータ化は分散削減手法とみなすこともできます。
</p>
<center><img src="images/fig19_11.png"></center>
<p class="margin-large">
図19.11　再パラメータ化トリックは、\(\mathbf z\) の直接サンプルを独立確率変数εのサンプルから計算されたサンプルに置き換えることにより、誤差信号がエンコーダネットワークに逆伝播できるようにします。結果として得られるモデルは、勾配ベースの最適化を使用してトレーニングし、エンコーダーネットワークとデコーダーネットワークの両方のパラメーターを学習できます。
</p>
<p>
したがって、特定のモデリング仮定を使用した VAE の完全な誤差関数は次のようになります。
\[
\mathcal L=\sum_n\left\{\frac{1}{2}\sum_{j=1}^M\{1+\ln\sigma_{nj}^2-\mu_{nj}^2-\sigma_{nj}^2\}+\frac{1}{L}\sum_{l=1}^L \ln p\left(\mathbf x_n|\mathbf z_n^{(l)},\mathbf w\right)\right\} \tag{19.19}
\]
ここで、\(\mathbf z_n^{(l)}\) には \(\mathbf z_{nj}^{(l)} = σ_{nj}ε^{(l)}＋μ_{nj}\) という成分があり、\(μ_{nj} = μ_j(\mathbf x_n, \boldsymbol{\phi})\) および \(σ_{nj} = σ_j(\mathbf x_n, \boldsymbol{\phi})\) であり、(19.19)の \(n\) に関する合計は ミニバッチ内のデータポイント。各データ点 \(\mathbf x\) のサンプル数 \(L\) は通常 1 に設定され、単一のサンプルのみが使用されます。これにより境界のノイズの多い推定が得られますが、すでにノイズの多い確率的勾配最適化ステップの一部を形成し、全体としてはより効率的な最適化につながります。
</p>
<p>
VAE トレーニングは次のように要約できます。ミニバッチ内の各データポイントについて、エンコーダネットワークを介して順伝播して近似潜在分布の平均と分散を評価し、再パラメータ化トリックを使用してこの分布からサンプリングし、これらのサンプルをデコーダネットワークを介して伝播して ELBO(19.19)を評価します。次に、\(\mathbf w\) および \(\boldsymbol{\phi}\) に関する勾配が自動微分を使用して評価されます。VAE トレーニングは アルゴリズム19.1 にまとめられていますが、明確にするために、これが一般的にミニバッチを使用して行われることは省略されています。モデルがトレーニングされると、エンコーダーネットワークは破棄され、以前の \(p(\mathbf z)\) からサンプリングし、デコーダーネットワークを順方向に伝播してデータ空間内のサンプルを取得することによって新しいデータポイントが生成されます。
</p>
<p>
\[
\boxed{
\begin{array}{l}
\textbf{アルゴリズム 19.1:　変分オートエンコーダーのトレーニング} \\
\hline
入力：学習データセット \mathcal D=\{\mathbf x_1, \cdots, \mathbf x_N\} \\
　　　エンコーダーネットワーク \{\mu_j(\mathbf x_n, \boldsymbol{\phi}),\sigma_j^2(\mathbf x_n, \boldsymbol{\phi})\},　j\in\{1,\cdots,M\} \\
　　　デコーダーネットワーク \mathbf g(\mathbf z,\mathbf w) \\
　　　初期重みベクトル \mathbf w, \boldsymbol{\phi} \\
　　　学習率 \eta \\
出力：最終重みベクトル \mathbf w, \boldsymbol{\phi} \\
\hline
repeat \\
　\mid \mathcal L\leftarrow 0 \\
　\mid for　j\in\{1,\cdots,M\}　do \\
　\mid　\mid\epsilon_{nj}\sim\mathcal N(0,1) \\
　\mid　\mid z_{nj}\leftarrow \mu_j(\mathbf x_n,\boldsymbol{\phi})\epsilon_{nj}+\sigma_j^2(\mathbf x_n, \boldsymbol{\phi}) \\
　\mid　\mid \mathcal L\leftarrow\mathcal L+\frac{1}{2}\{1+\ln\sigma_{nj}^2-\mu_{nj}^2-\sigma_{nj}^2\} \\
　\mid end\;for \\
　\mid \mathcal L\leftarrow \mathcal L+\ln p(\mathbf x_n|\mathbf z_n, \mathbf w) \\
　\mid \mathbf w\leftarrow \mathbf w+\eta\nabla_{\mathbf w}\mathcal L　//デコーダー重み更新 \\
　\mid  \boldsymbol{\phi}\leftarrow\boldsymbol{\phi}+\eta\nabla_{\boldsymbol{\phi}} \mathcal L　// エンコーダー重み更新\\
unitl　収束するまで \\
return　\mathbf w,\boldsymbol{\phi}
\end{array}
}
\]
</p>
<p>
トレーニング後、モデルが新しいテストポイント \(\hat{\mathbf x}\) をどの程度適切に表現しているかを評価したい場合があります。対数尤度は扱いにくいため、下界 \(\mathcal L\) を近似値として使用できます。これを推定するには、\(q(\mathbf z|\hat{\mathbf x},\boldsymbol{\phi})\) からサンプリングすることができます。これは、\(p(\mathbf z)\) からサンプリングするよりも正確な推定値が得られるためです。
</p>
<p>
VAE にはさまざまなバリエーションがあります。画像データに適用される場合、通常、エンコーダは畳み込みに基づき、デコーダは転置畳み込みに基づきます。条件付き VAE では、エンコーダとデコーダの両方が追加の入力として条件変数 \(\mathbf c\) を受け取ります。たとえば、\(\mathbf c\) がオブジェクトクラスを表すオブジェクトのイメージを生成したい場合があります。潜在空間事前分布 \(p(\mathbf z)\) も単純なガウス分布にすることも、別のニューラルネットワークによって与えられる条件付き分布 \(p(\mathbf z|\mathbf c)\) に拡張することもできます。トレーニングとテストは以前と同様に続行されます。
</p>
<p>
ELBO(19.14)の最初の項は、エンコーダー分布 \(q(\mathbf z|\mathbf x, \boldsymbol{\phi})\) が前の \(p(\mathbf z)\) に近づくように促すため、トレーニングされたモデルが \(p(\mathbf z)\) からサンプリングすることで生成的に実行します。VAE をトレーニングする場合、変分分布 \(q(\mathbf z|\mathbf x, \boldsymbol{\phi})\) が事前分布 \(p(\mathbf z)\) に収束し、\(\mathbf x\) に依存しなくなるため有益でなくなるという問題が発生する可能性があります。実際には、潜在コードは無視されます。これは事後分布崩壊(posterior collapse)として知られています。この症状としては、入力を取得してエンコードしてからデコードすると、再構成が不十分でぼやけて見えることが挙げられます。この場合、カルバック・ライブラーダイバージェンス \(KL(q(\mathbf z|\mathbf x, \boldsymbol{\phi})||p(\mathbf z))\) はゼロに近くなります。
</p>
<p>
潜在コードが圧縮されていない場合、別の問題が発生します。これは、高精度の再構成を特徴としますが、\(p(\mathbf z)\) をサンプリングし、サンプルをデコーダネットワークに渡すことによって生成される出力の品質が低く、トレーニングデータに似ていません。この場合、カルバックライブラーダイバージェンスは比較的大きく、訓練されたシステムは事前のものとは大きく異なる変分分布を持っているため、事前のものからのサンプルは現実的な出力を生成しません。
</p>
<p>
どちらの問題も、カルバック・ライブラーダイバージェンスの正則化の有効性を制御する係数((19.14)の最初の項の前に)を導入することで解決できます。通常は β> 1 (Higgins et al., 2017)。サンプルが貧弱な場合は β を増やすことができ、サンプルが貧弱に見える場合は減らすことができます。β の値は、小さな値から開始してトレーニング中に徐々に増加するアニーリングスケジュールに従うように設定することもできます。
</p>
<p>
最後に、ガウス出力分布の平均を表すデコーダネットワーク \(\mathbf g(\mathbf z, \mathbf w)\) を検討したことに注意してください。VAE を拡張して、ガウス分布の分散、またはより一般的には他のより複雑な分布を特徴付けるパラメーターを表す出力を含めることができます。
</p>
    </body>
</html>